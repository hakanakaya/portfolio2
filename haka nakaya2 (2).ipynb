{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28958675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ec1f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d472d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(file = 'C:/Users/ukadi/Desktop/txt files/positive reviews amazon.txt',mode = 'r')\n",
    "lines = file.readlines()\n",
    "document = ''\n",
    "for line in lines:\n",
    "    amazon_reviews = line.split('\\t')[2]\n",
    "    document += amazon_reviews + '\\n'\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e3cb5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "251f7b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwords_with_pos_tags = pos_tag(words)\\nfor word, pos_tag in words_with_pos_tags:\\n    print(word, pos_tag)\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "words_with_pos_tags = pos_tag(words)\n",
    "for word, pos_tag in words_with_pos_tags:\n",
    "    print(word, pos_tag)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "211f6e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\\nfor first_element, second_element in bigrams_with_pos_tags:\\n    print(first_element, second_element)\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\n",
    "for first_element, second_element in bigrams_with_pos_tags:\n",
    "    print(first_element, second_element)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "43287650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\\nfor first_element, second_element in bigrams_with_pos_tags:\\n    first_word_of_bigram , first_word_pos_tags = first_element[0], first_element[1]\\n    second_word_of_bigram, second_word_pos_tags = second_element[0], second_element[1]\\n    print(first_word_of_bigram,first_word_pos_tags,second_word_of_bigram, second_word_pos_tags)\\n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\n",
    "for first_element, second_element in bigrams_with_pos_tags:\n",
    "    first_word_of_bigram , first_word_pos_tags = first_element[0], first_element[1]\n",
    "    second_word_of_bigram, second_word_pos_tags = second_element[0], second_element[1]\n",
    "    print(first_word_of_bigram,first_word_pos_tags,second_word_of_bigram, second_word_pos_tags)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d37b914e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 18) (541683211.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[111], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 18)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "data = document  # Replace with your dataset\n",
    "\n",
    "tokens = nltk.word_tokenize(data)\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "bigram_freq = finder.ngram_fd.items()\n",
    "\n",
    "sorted_bigrams = sorted(bigram_freq, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "top_40_bigrams = sorted_bigrams[:40]\n",
    "for bigram, freq in top_40_bigrams:\n",
    "    print(bigram, freq)\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7d9ed77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequency_of_bigrams(bigrams_with_pos_tags):\n",
    "    bigrams_with_frequencies= {}\n",
    "    for first_element, second_element in bigrams_with_pos_tags:\n",
    "        first_word_of_bigram, first_word_pos_tag = first_element[0], first_element[1]\n",
    "        second_word_of_bigram, second_word_pos_tag = second_element[0], second_element[1]\n",
    "        if (first_word_of_bigram, second_word_of_bigram) in bigrams_with_frequencies:\n",
    "            bigrams_with_frequencies[(first_word_of_bigram,second_word_of_bigram)] +=1\n",
    "        else:\n",
    "            bigrams_with_frequencies[(first_word_of_bigram,second_word_of_bigram)] =1\n",
    "    return bigrams_with_frequencies\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cbb78838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigrams_with_frequencies = compute_frequency_of_bigrams(bigrams_with_pos_tags)\\nfor bigram in bigrams_with_frequencies:\\n    print(bigram, bigrams_with_frequencies[bigram])\\n'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"bigrams_with_frequencies = compute_frequency_of_bigrams(bigrams_with_pos_tags)\n",
    "for bigram in bigrams_with_frequencies:\n",
    "    print(bigram, bigrams_with_frequencies[bigram])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e7bac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('13', 'year') 3\n",
      "('year', 'old') 34\n",
      "('old', 'fps') 1\n",
      "('fps', 'fan') 2\n",
      "('fan', 'speaking') 1\n",
      "('speaking', 'here') 1\n",
      "('here', 'and') 16\n",
      "('and', 'you') 497\n",
      "('you', 'have') 723\n",
      "('have', 'my') 5\n",
      "('my', 'word') 3\n",
      "('word', 'that') 2\n",
      "('that', 'this') 166\n",
      "('this', 'is') 729\n",
      "('is', 'one') 260\n",
      "('one', 'of') 685\n",
      "('of', 'the') 3136\n",
      "('the', 'best') 1013\n",
      "('best', 'fps') 4\n",
      "('fps', 'this') 1\n",
      "('this', 'fan') 1\n",
      "('fan', 'has') 1\n",
      "('has', 'played') 10\n",
      "('played', 'ever') 1\n",
      "('ever', '.') 77\n",
      "('.', 'The') 3395\n",
      "('The', 'graphics') 345\n",
      "('graphics', 'are') 507\n",
      "('are', 'very') 158\n",
      "('very', 'good') 125\n",
      "('good', ',') 159\n",
      "(',', 'if') 265\n",
      "('if', 'not') 41\n",
      "('not', 'sloppy') 1\n",
      "('sloppy', 'at') 1\n",
      "('at', 'some') 15\n",
      "('some', 'times') 1\n",
      "('times', ',') 53\n",
      "(',', 'and') 4152\n",
      "('and', 'the') 1366\n"
     ]
    }
   ],
   "source": [
    "top_40_bigrams = list(bigrams_with_frequencies.items())[0:40]\n",
    "for bigram, freq in top_40_bigrams:\n",
    "    print(bigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "67f40986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0eb16ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 'and') 4152\n",
      "('.', 'The') 3395\n",
      "('of', 'the') 3136\n",
      "('this', 'game') 2977\n",
      "('.', 'I') 2608\n",
      "(',', 'but') 2509\n",
      "('the', 'game') 2421\n",
      "('is', 'a') 1706\n",
      "(',', 'the') 1679\n",
      "('.', 'It') 1673\n",
      "('in', 'the') 1666\n",
      "('game', 'is') 1630\n",
      "('!', '!') 1442\n",
      "('and', 'the') 1366\n",
      "('.', 'This') 1336\n",
      "('it', \"'s\") 1325\n",
      "('you', 'can') 1317\n",
      "(',', 'you') 1316\n",
      "('game', '.') 1314\n",
      "('.', 'You') 1207\n",
      "('to', 'the') 1195\n",
      "('on', 'the') 1152\n",
      "(',', 'I') 1139\n",
      "('is', 'the') 1120\n",
      "('if', 'you') 1080\n",
      "('&', 'quot') 1018\n",
      "('quot', ';') 1018\n",
      "('the', 'best') 1013\n",
      "('for', 'the') 1010\n",
      "(',', 'it') 978\n",
      "('it', 'is') 935\n",
      "('do', \"n't\") 918\n",
      "('game', ',') 915\n",
      "('.', 'If') 785\n",
      "('it', '.') 774\n",
      "('with', 'the') 760\n",
      "('.', 'There') 744\n",
      "('to', 'be') 742\n",
      "('I', 'have') 735\n",
      "('this', 'is') 729\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "bigrams_with_frequencies_sorted = dict(sorted(bigrams_with_frequencies.items(), key=operator.itemgetter(1), reverse=True))\n",
    "count = 0\n",
    "for bigram in bigrams_with_frequencies_sorted:\n",
    "    print(bigram, bigrams_with_frequencies_sorted[bigram])\n",
    "    count+=1\n",
    "    if count == 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e71b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "bigrams_with_frequencies_sorted = dict(sorted(bigrams_with_frequencies.items(), key=operator.itemgetter(1), reverse=True))\n",
    "count = 0\n",
    "for bigram in bigrams_with_frequencies_sorted:\n",
    "    print(bigram, bigrams_with_frequencies_sorted[bigram])\n",
    "    count += 1\n",
    "    if count == 40:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "27d50074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "# Create bigrams\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(top_40_bigrams)\n",
    "\n",
    "# Apply frequency filter to remove low frequency bigrams\n",
    "finder.apply_freq_filter(2)\n",
    "\n",
    "# Apply part-of-speech filter to remove non-collocations\n",
    "finder.apply_word_filter(lambda w: w[1] in ['NN', 'JJ'])\n",
    "\n",
    "# Get the 40 most important bigrams according to their frequency\n",
    "bigrams = finder.nbest(bigram_measures.raw_freq, 40)\n",
    "\n",
    "# Print the top 40 bigrams\n",
    "for bigram in bigrams:\n",
    "    print(bigram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33fd250c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('this', 'is')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2636035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('13', 'year'), 3), (('year', 'old'), 34), (('old', 'fps'), 1), (('fps', 'fan'), 2), (('fan', 'speaking'), 1), (('speaking', 'here'), 1), (('here', 'and'), 16), (('and', 'you'), 497), (('you', 'have'), 723), (('have', 'my'), 5), (('my', 'word'), 3), (('word', 'that'), 2), (('that', 'this'), 166), (('this', 'is'), 729), (('is', 'one'), 260), (('one', 'of'), 685), (('of', 'the'), 3136), (('the', 'best'), 1013), (('best', 'fps'), 4), (('fps', 'this'), 1), (('this', 'fan'), 1), (('fan', 'has'), 1), (('has', 'played'), 10), (('played', 'ever'), 1), (('ever', '.'), 77), (('.', 'The'), 3395), (('The', 'graphics'), 345), (('graphics', 'are'), 507), (('are', 'very'), 158), (('very', 'good'), 125), (('good', ','), 159), ((',', 'if'), 265), (('if', 'not'), 41), (('not', 'sloppy'), 1), (('sloppy', 'at'), 1), (('at', 'some'), 15), (('some', 'times'), 1), (('times', ','), 53), ((',', 'and'), 4152), (('and', 'the'), 1366)]\n"
     ]
    }
   ],
   "source": [
    "print(top_40_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6de4fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('old', 'fps'), 1), (('fps', 'fan'), 2), (('fan', 'speaking'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Function to filter bigrams based on specified POS tag patterns\n",
    "def filter_bigrams(bigrams):\n",
    "    filtered_bigrams = []\n",
    "    for bigram, count in bigrams:\n",
    "        # Tokenize the bigram and perform POS tagging\n",
    "        tokens = word_tokenize(' '.join(bigram))\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        # Get the POS tag sequence\n",
    "        pos_tags = ' '.join([tag for _, tag in tagged_tokens])\n",
    "        # Check if the POS tag sequence matches one of the specified patterns\n",
    "        if pos_tags in [\"JJ NN\", \"NN NN\", \"NNP NNP\", \"NNP NN\"]:\n",
    "            filtered_bigrams.append((bigram, count))\n",
    "    return filtered_bigrams\n",
    "\n",
    "# Original bigram list\n",
    "original_bigrams = top_40_bigrams\n",
    "\n",
    "# Filtered bigram list\n",
    "filtered_bigrams = filter_bigrams(original_bigrams)\n",
    "print(filtered_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b950ff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('&', 'quot') 752.0493468795355\n",
      "('quot', ';') 636.1718845917741\n",
      "('this', 'game') 388.58096070959\n",
      "('.', 'The') 348.33610674209433\n",
      "('Resident', 'Evil') 171.7725518747725\n",
      "('Tony', 'Hawk') 139.40507793887414\n",
      "(',', 'and') 138.3832532041335\n",
      "('!', '!') 138.1371082406977\n",
      "(',', 'but') 137.38009308790618\n",
      "('Theft', 'Auto') 137.2613772179829\n",
      "('Grand', 'Theft') 125.0035053221049\n",
      "('do', \"n't\") 105.2149984495618\n",
      "('.', 'It') 91.0676356972681\n",
      "('of', 'the') 89.78697359203838\n",
      "('replay', 'value') 79.21577464788733\n",
      "('Eternal', 'Darkness') 76.9578227124183\n",
      "('.', 'I') 72.42758785294401\n",
      "('May', 'Cry') 72.37334146713437\n",
      "('Star', 'Wars') 70.05022026431718\n",
      "('Final', 'Fantasy') 66.46363946739501\n",
      "('if', 'you') 63.10644884954688\n",
      "('you', 'can') 60.85104690069955\n",
      "('Devil', 'May') 59.786930330015714\n",
      "('Super', 'Smash') 54.512980572895394\n",
      "('ca', \"n't\") 53.19032377590342\n",
      "('it', \"'s\") 52.32252886484872\n",
      "('Max', 'Payne') 50.653\n",
      "('.', 'This') 50.37957920683307\n",
      "('Golden', 'Sun') 49.36371168185584\n",
      "('the', 'game') 46.529519757334604\n",
      "('.', 'You') 45.64415855338052\n",
      "('gon', 'na') 40.205128205128204\n",
      "('If', 'you') 33.28668461341513\n",
      "('It', \"'s\") 33.22374243758343\n",
      "('game', 'is') 32.80099010698883\n",
      "('Crazy', 'Taxi') 32.63304924242424\n",
      "('Pro', 'Skater') 29.30236612702366\n",
      "('Smash', 'Bros.') 28.90091513595365\n",
      "('the', 'best') 28.53141076052019\n",
      "('Mega', 'Man') 27.239054629988377\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "# Load the Amazon dataset (replace 'amazon_dataset.txt' with the path to your dataset)\n",
    "file = open(file = 'C:/Users/ukadi/Desktop/txt files/positive reviews amazon.txt',mode = 'r')\n",
    "lines = file.readlines()\n",
    "amazon_dataset = ''\n",
    "for line in lines:\n",
    "    amazon_reviews = line.split('\\t')[2]\n",
    "    amazon_dataset += amazon_reviews + '\\n'\n",
    "file.close()\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(amazon_dataset)\n",
    "\n",
    "# Apply preprocessing steps if necessary (e.g., lowercase conversion, stopwords removal, etc.)\n",
    "\n",
    "# Create a BigramCollocationFinder\n",
    "bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Compute mutual information for each bigram\n",
    "bigram_scored = bigram_finder.score_ngrams(BigramAssocMeasures.mi_like)\n",
    "\n",
    "# Sort the bigrams based on mutual information\n",
    "sorted_bigrams = sorted(bigram_scored, key=lambda x: -x[1])\n",
    "\n",
    "# Display the top 40 collocations\n",
    "top_40_collocations = sorted_bigrams[:40]\n",
    "for bigram, score in top_40_collocations:\n",
    "    print(bigram, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8507b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
